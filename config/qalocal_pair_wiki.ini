[COMMON]
datasets_dir = data
dataset_name = wiki
wordvec_initialization = word2vec
wordvec_path = glove/glove.6B.50d.txt
optimizer = rmsprop
batch_size = 6
epochs = 80
eval_dir = eval
embedding_trainable = True
network_type = local_mixture
init_mode = he
activation = sigmoid
amplitude_l2 = 0.0000005
phase_l2 = 0
dropout_rate_embedding = 0.8
dropout_rate_probs = 0.9
dense_l2 = 0
measurement_size  = 300
lr = 0.05
sentiment_dic_file = sentiment_dic/sentiment_dic.txt
ngram_value = 2,3,5,7
clean = 1
clean_sentence = 1
random_init = 0 ; attention
match_type = pairwise
margin = 0.1
pooling_type = max
steps_per_epoch = 50
distance_type = 6
onehot = 0
max_len = 50
output_file = output_pair_wiki.txt
train_verbose = 0
remove_punctuation= 1
stem = 0
remove_stowords = 0